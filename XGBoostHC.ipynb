{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import gc\n",
        "\n",
        "# Mengabaikan peringatan untuk kejelasan output\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "au4iZuJ_B7PB"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Fungsi Pemuatan Data (Load Data) ---\n",
        "def load_data():\n",
        "    \"\"\"Memuat semua file CSV.\"\"\"\n",
        "    file_paths = {\n",
        "        \"train\": \"application_train.csv\",\n",
        "        \"test\": \"application_test.csv\",\n",
        "        \"bureau\": \"bureau.csv\",\n",
        "        \"bureau_balance\": \"bureau_balance.csv\",\n",
        "        \"pos_cash\": \"POS_CASH_balance.csv\",\n",
        "        \"credit_card\": \"credit_card_balance.csv\",\n",
        "        \"previous\": \"previous_application.csv\",\n",
        "        \"installments\": \"installments_payments.csv\"\n",
        "    }\n",
        "\n",
        "    data = {}\n",
        "    print(\"Memuat data...\")\n",
        "    for name, path in file_paths.items():\n",
        "        try:\n",
        "            # Gunakan dtype object=str untuk mencegah warning pada kolom ID\n",
        "            data[name] = pd.read_csv(path, low_memory=False)\n",
        "            print(f\"  âœ… '{name}' dimuat: {data[name].shape[0]} baris.\")\n",
        "        except FileNotFoundError:\n",
        "            print(f\"  âŒ ERROR: File '{path}' tidak ditemukan. Lewati.\")\n",
        "    return data"
      ],
      "metadata": {
        "id": "r9Bok54aB_LR"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 2. Fungsi Agregasi Bureau dan Bureau Balance ---\n",
        "def bureau_and_balance_agg(bureau, bureau_balance):\n",
        "    \"\"\"\n",
        "    Melakukan agregasi bertingkat: bureau_balance -> bureau -> SK_ID_CURR.\n",
        "    \"\"\"\n",
        "    print(\"\\n[START] Feature Engineering: Bureau & Bureau Balance...\")\n",
        "\n",
        "    # Agregasi bureau_balance (bb) ke SK_ID_BUREAU\n",
        "    bb_counts = bureau_balance.groupby('SK_ID_BUREAU')['STATUS'].value_counts(normalize=True).unstack(fill_value=0)\n",
        "    bb_counts.columns = [f'BB_STATUS_{col}_RATIO' for col in bb_counts.columns]\n",
        "    bb_agg = bureau_balance.groupby('SK_ID_BUREAU').agg(\n",
        "        BB_MONTHS_COUNT=('MONTHS_BALANCE', 'count'),\n",
        "        BB_MONTHS_MEAN=('MONTHS_BALANCE', 'mean')\n",
        "    )\n",
        "    bb_final = pd.merge(bb_counts, bb_agg, left_index=True, right_index=True, how='outer').reset_index()\n",
        "    bureau_merged = pd.merge(bureau, bb_final, on='SK_ID_BUREAU', how='left')\n",
        "\n",
        "    # Agregasi bureau_merged ke SK_ID_CURR\n",
        "    bureau_agg = bureau_merged.groupby('SK_ID_CURR').agg({\n",
        "        'SK_ID_BUREAU': 'count',\n",
        "        'AMT_CREDIT_SUM': ['mean', 'max', 'sum'],\n",
        "        'DAYS_CREDIT': ['mean', 'max'],\n",
        "        'CREDIT_DAY_OVERDUE': ['mean', 'max'],\n",
        "        'BB_MONTHS_COUNT': ['mean', 'sum']\n",
        "    })\n",
        "\n",
        "    bureau_agg.columns = [f'BUREAU_{\"_\".join(col).upper()}' for col in bureau_agg.columns]\n",
        "    bureau_agg = bureau_agg.reset_index()\n",
        "\n",
        "    # Gabungkan semua fitur kategorikal BB yang diagregasi\n",
        "    bb_status_cols = [col for col in bb_final.columns if 'BB_STATUS' in col]\n",
        "    for col in bb_status_cols:\n",
        "        status_agg = bureau_merged.groupby('SK_ID_CURR')[col].agg(['mean']).reset_index()\n",
        "        status_agg.columns = ['SK_ID_CURR', f'BUREAU_{col}_MEAN']\n",
        "        bureau_agg = pd.merge(bureau_agg, status_agg, on='SK_ID_CURR', how='left')\n",
        "\n",
        "    print(\"[END] Feature Engineering: Bureau & Bureau Balance selesai.\")\n",
        "    return bureau_agg"
      ],
      "metadata": {
        "id": "Bh1JRdb3CFuY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 3. Fungsi Main Execution (Modifikasi untuk Integrasi XGBoost) ---\n",
        "def run_full_pipeline():\n",
        "\n",
        "    data = load_data()\n",
        "\n",
        "    if 'train' not in data or 'test' not in data:\n",
        "        print(\"\\n[GAGAL] Data aplikasi utama (train/test) tidak lengkap.\")\n",
        "        return\n",
        "\n",
        "    # Inisialisasi DataFrame akhir\n",
        "    df_train_final = data['train'].copy()\n",
        "    df_test_final = data['test'].copy()\n",
        "\n",
        "    # --- PROSES A: Agregasi Tabel Pendukung ---\n",
        "    all_features = {}\n",
        "\n",
        "    # A. Bureau & Bureau Balance\n",
        "    if 'bureau' in data and 'bureau_balance' in data:\n",
        "        bureau_features = bureau_and_balance_agg(data['bureau'], data['bureau_balance'])\n",
        "        all_features['bureau'] = bureau_features\n",
        "\n",
        "    # --- PROSES B: Penggabungan (Merge) Akhir ke Data Aplikasi ---\n",
        "\n",
        "    print(\"\\n[START] Penggabungan Fitur ke Train dan Test...\")\n",
        "\n",
        "    for name, features_df in all_features.items():\n",
        "        df_train_final = pd.merge(df_train_final, features_df, on='SK_ID_CURR', how='left')\n",
        "        df_test_final = pd.merge(df_test_final, features_df, on='SK_ID_CURR', how='left')\n",
        "        print(f\"  âœ… Fitur dari '{name}' berhasil digabungkan.\")\n",
        "\n",
        "    # Hapus data mentah yang besar dari memori\n",
        "    del data; gc.collect()\n",
        "\n",
        "    print(f\"\\nDimensi Data Training Final: {df_train_final.shape}\")\n",
        "    print(f\"Dimensi Data Testing Final: {df_test_final.shape}\")\n",
        "\n",
        "    # --- PROSES C: Persiapan Data untuk Model XGBoost ---\n",
        "\n",
        "    print(\"\\n--- Persiapan Data untuk Pemodelan XGBoost ---\")\n",
        "\n",
        "    # 1. Pemisahan Final Fitur (X) dan Target (y)\n",
        "\n",
        "    # Simpan ID Pelanggan dari Test Set untuk file submission\n",
        "    test_ids = df_test_final['SK_ID_CURR']\n",
        "\n",
        "    # Hapus ID Pelanggan dan TARGET dari fitur training (X_train)\n",
        "    X_train_full = df_train_final.drop(['TARGET', 'SK_ID_CURR'], axis=1)\n",
        "    y_train = df_train_final['TARGET']\n",
        "\n",
        "    # Hapus ID Pelanggan dari fitur testing (X_test)\n",
        "    X_test_full = df_test_final.drop('SK_ID_CURR', axis=1)\n",
        "\n",
        "    # 2. Identifikasi Tipe Kolom (Hanya menggunakan kolom yang ada di kedua set)\n",
        "\n",
        "    # Isi NaN pada kolom kategorikal di train/test agar tidak gagal di OneHotEncoder\n",
        "    X_train_full[X_train_full.select_dtypes(include='object').columns] = X_train_full.select_dtypes(include='object').fillna('Missing')\n",
        "    X_test_full[X_test_full.select_dtypes(include='object').columns] = X_test_full.select_dtypes(include='object').fillna('Missing')\n",
        "\n",
        "    numerical_cols = X_train_full.select_dtypes(include=np.number).columns.tolist()\n",
        "    categorical_cols = X_train_full.select_dtypes(include='object').columns.tolist()\n",
        "\n",
        "    # --- PROSES D: Pipelining Pra-pemrosesan & Model XGBoost ---\n",
        "\n",
        "    # Pra-pemrosesan untuk kolom numerik\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # Pra-pemrosesan untuk kolom kategorikal\n",
        "    categorical_transformer = Pipeline(steps=[\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ])\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numerical_transformer, numerical_cols),\n",
        "            ('cat', categorical_transformer, categorical_cols)\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "\n",
        "    # Menghitung rasio kelas untuk scaling positif di XGBoost\n",
        "    scale_pos_weight = y_train.value_counts()[0] / y_train.value_counts()[1]\n",
        "\n",
        "    # Model Pipeline Penuh\n",
        "    xgb_model = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', XGBClassifier(\n",
        "            objective='binary:logistic',\n",
        "            eval_metric='auc',\n",
        "            n_estimators=1000,\n",
        "            learning_rate=0.02,\n",
        "            max_depth=4,\n",
        "            scale_pos_weight=scale_pos_weight,\n",
        "            n_jobs=-1,\n",
        "            random_state=42,\n",
        "            use_label_encoder=False # Harus False untuk versi XGBoost terbaru\n",
        "        ))\n",
        "    ])\n",
        "\n",
        "    print(\"\\n[START] Melatih Model XGBoost (1000 Trees)...\")\n",
        "    xgb_model.fit(X_train_full, y_train)\n",
        "    print(\"[END] Pelatihan Model Selesai.\")\n",
        "\n",
        "    # --- PROSES E: Evaluasi dan Prediksi ---\n",
        "\n",
        "    # Evaluasi pada Training Set\n",
        "    y_train_pred_proba = xgb_model.predict_proba(X_train_full)[:, 1]\n",
        "    train_auc = roc_auc_score(y_train, y_train_pred_proba)\n",
        "\n",
        "    print(f\"\\n=============================================\")\n",
        "    print(f\"ðŸŽ‰ Kinerja Model XGBoost (Training Set - AUC): {train_auc:.4f}\")\n",
        "    print(\"=============================================\")\n",
        "\n",
        "    # Prediksi pada Testing Set (Probabilitas)\n",
        "    test_predictions_proba = xgb_model.predict_proba(X_test_full)[:, 1]\n",
        "\n",
        "    # Pembuatan Submission File\n",
        "    submission = pd.DataFrame({\n",
        "        'SK_ID_CURR': test_ids,\n",
        "        'TARGET': test_predictions_proba\n",
        "    })\n",
        "\n",
        "    submission.to_csv('xgboost_submission.csv', index=False)\n",
        "\n",
        "    print(\"\\nâœ… Prediksi Data Test Selesai dan disimpan ke 'xgboost_submission.csv'\")\n",
        "    print(\"Head dari file submission:\")\n",
        "    print(submission.head())\n",
        "\n",
        "# Eksekusi script utama\n",
        "if __name__ == \"__main__\":\n",
        "    run_full_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Js9SZ8qLCOjL",
        "outputId": "3e776526-8c1b-4471-dbc7-b2ed4521d525"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memuat data...\n",
            "  âœ… 'train' dimuat: 307511 baris.\n",
            "  âœ… 'test' dimuat: 48744 baris.\n",
            "  âœ… 'bureau' dimuat: 1716428 baris.\n",
            "  âœ… 'bureau_balance' dimuat: 27299925 baris.\n",
            "  âœ… 'pos_cash' dimuat: 10001358 baris.\n",
            "  âœ… 'credit_card' dimuat: 3840312 baris.\n",
            "  âœ… 'previous' dimuat: 1670214 baris.\n",
            "  âœ… 'installments' dimuat: 13605401 baris.\n",
            "\n",
            "[START] Feature Engineering: Bureau & Bureau Balance...\n",
            "[END] Feature Engineering: Bureau & Bureau Balance selesai.\n",
            "\n",
            "[START] Penggabungan Fitur ke Train dan Test...\n",
            "  âœ… Fitur dari 'bureau' berhasil digabungkan.\n",
            "\n",
            "Dimensi Data Training Final: (307511, 140)\n",
            "Dimensi Data Testing Final: (48744, 139)\n",
            "\n",
            "--- Persiapan Data untuk Pemodelan XGBoost ---\n",
            "\n",
            "[START] Melatih Model XGBoost (1000 Trees)...\n",
            "[END] Pelatihan Model Selesai.\n",
            "\n",
            "=============================================\n",
            "ðŸŽ‰ Kinerja Model XGBoost (Training Set - AUC): 0.7856\n",
            "=============================================\n",
            "\n",
            "âœ… Prediksi Data Test Selesai dan disimpan ke 'xgboost_submission.csv'\n",
            "Head dari file submission:\n",
            "   SK_ID_CURR    TARGET\n",
            "0      100001  0.326874\n",
            "1      100005  0.619582\n",
            "2      100013  0.246138\n",
            "3      100028  0.255137\n",
            "4      100038  0.642393\n"
          ]
        }
      ]
    }
  ]
}